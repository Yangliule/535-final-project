{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA\n",
    "#### Team members: Liule Yang, Zhiwen Xu, Yuxuan Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is one of the most popular dimensionality reduction and data visualization right now (Bishop, 561). PCA can extract linear features of a matrix input data and some meaningful analysis can be performed based on that. PCA can be performed through eigen-decomposition as well as singular value decomposition (SVD). PCA works well in some cases, for example, when dealing with DNA sequences, it can achieve satisfactory results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, PCA can only extract linear features. When the data is not linearly separable, we need to do a kernel trick and here we need kernel PCA (KPCA). With the KPCA, we can extract nonlinear features. Common kernels for KPCA include polynomial kernel, Gaussian kernel, and Laplace kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The eigen decomposition implementation of PCA\n",
    "\n",
    "The first type of algorithm is utilizing the information from eigenvalues and eigenvectors. First, the input matrix will be standardized by deducting mean of the matrix. Then, the covariance matrix of the input matrix will be computed, and the eigenvector and eigenvalue will be computed based on the covariance matrix. Then, sort the eigenvectors based on eigenvalues from large to small, and then select the top n components to make transformation of the original input matrix to a matrix with n features (n columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_pca(m, n_components = 2):\n",
    "    # compute the mean and make the input matrix centered\n",
    "    mean = np.mean(m,0)\n",
    "    centered_m = m - mean\n",
    "    num_rows, num_cols = centered_m.shape\n",
    "    # compute covariance matrix\n",
    "    cov_matrix = np.cov(np.transpose(centered_m))\n",
    "    # compute eigenvector and eigenvalue\n",
    "    eig_val_cov, eig_vec_cov = np.linalg.eig(cov_matrix)\n",
    "    # sort the eigenvalue and eigenvector pair by the order of eigenvector from large to small\n",
    "    eig_pairs = [(np.abs(eig_val_cov[i]), eig_vec_cov[:,i]) for i in range(len(eig_val_cov))]\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "    # transform to the reduced dimension dataset\n",
    "    transformation_maxtrix = np.hstack((eig_pairs[k][1].reshape(num_cols,1) for k in range(n_components)))\n",
    "    reduced = (transformation_maxtrix.transpose()).dot(centered_m.transpose())\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The SVD implementation of PCA\n",
    "\n",
    "The PCA can also be performed using SVD. The only difference is that we are using sigular value this time instead of eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_pca(m, n_components = 2):\n",
    "    # compute the mean and make the input matrix centered\n",
    "    mean = np.mean(m,0)\n",
    "    centered_m = m - mean\n",
    "    # perform singular value decomposition\n",
    "    U, S, V_transpose = np.linalg.svd(centered_m, full_matrices=False)\n",
    "    S = np.diag(S)\n",
    "    # reduce the dimensionality\n",
    "    reduced = U[:, 0:n_components].dot(S[0:n_components, 0:n_components])\n",
    "    return reduced.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
